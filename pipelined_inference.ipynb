{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Install required package***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpewPOuxYZrD",
        "outputId": "f79d55fc-ef2e-4721-92fb-8ad3ca39fd32"
      },
      "outputs": [],
      "source": [
        "! pip install ultralytics\n",
        "! pip install yt-dlp\n",
        "! pip install openai-whisper\n",
        "! pip install ollama\n",
        "! curl -fsSL https://ollama.com/install.sh | sh\n",
        "! ollama pull openbmb/minicpm-o2.6:8b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***list up video file path manually***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "test_video_dir = os.path.join(\"data\",\"20250913\", \"test\")\n",
        "video_files = [ os.path.join(test_video_dir, s) for s in [\"abnormal1.mp4\", \"abnormal2.mp4\", \"normal1.mp4\", \"normal2.mp4\", \"normal3.mp4\", \"normal4.mp4\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Download videos in url list and add to video file path***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgraPiDfXiy5",
        "outputId": "9b393bf8-66f9-4404-8fd3-3ae8a21435fb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yt_dlp as ydl\n",
        "\n",
        "def download_video(url, label=\"normal\", out_dir=\"videos\"):\n",
        "    # 라벨 하위 폴더 생성\n",
        "    save_dir = os.path.join(out_dir, label)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'mp4',\n",
        "        'outtmpl': os.path.join(save_dir, '%(title)s.%(ext)s'),\n",
        "        'noplaylist': True,\n",
        "        'hls_prefer_native': True,  # HLS fragment 안정적으로 다운로드\n",
        "        'retries': 10,\n",
        "        'quiet': False\n",
        "    }\n",
        "\n",
        "    with ydl.YoutubeDL(ydl_opts) as y:\n",
        "        info = y.extract_info(url, download=True)\n",
        "        filename = y.prepare_filename(info)\n",
        "        return filename, label\n",
        "\n",
        "# URL + 라벨 매핑\n",
        "urls_labels = [\n",
        "    ('https://url/to/your/video1', 'normal'),\n",
        "    ('https://url/to/your/video2', 'normal2'),\n",
        "]\n",
        "\n",
        "video_files = [download_video(url, label) for url, label in urls_labels]\n",
        "\n",
        "print(\"다운로드 완료:\")\n",
        "for v, lbl in video_files:\n",
        "    print(f\"{v} -> {lbl}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Parse label from directory path***\n",
        "- sub folder name contains its label\n",
        "- video_files_with_label is a list of dict\n",
        "- each dict consists of its file path and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er6kIvo2Z2BO",
        "outputId": "52ebe267-3cc4-4ee5-9914-d023f1d54782"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "video_files = []\n",
        "for root, dirs, files in os.walk(test_video_dir):\n",
        "   for f in files:\n",
        "      video_files.append(os.path.join(root ,f))\n",
        "\n",
        "video_files_with_label = []\n",
        "for path in video_files:\n",
        "    label = os.path.basename(os.path.dirname(path))\n",
        "    video_files_with_label.append({'path':path, 'label':label})\n",
        "\n",
        "print(\"찾은 동영상 파일:\")\n",
        "for video in video_files_with_label:\n",
        "    for k, v in video.items():\n",
        "      print(k, v)\n",
        "frame_interval = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Download latest classification model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ0l_p7NZQI-",
        "outputId": "17aaca35-5d82-4d57-d757-f4ad1f2f3db0"
      },
      "outputs": [],
      "source": [
        "! wget https://raw.githubusercontent.com/suriseven/abnormality_classifier/main/20250920_epoch30.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Load downloaded model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBHkNfdHZG3L",
        "outputId": "97d92437-3928-48e0-dee0-70ca21d9fb82"
      },
      "outputs": [],
      "source": [
        "# You are required to install ultralytics first\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the attached classifier\n",
        "model = YOLO(r\"runs\\classify\\train17\\weights\\epoch30.pt\")\n",
        "\n",
        "# Frame sampling interval\n",
        "frame_interval = 1  # process every 10th frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Check hash value for downloaded model***\n",
        "- In this example, the hash value should be\n",
        "    ```\n",
        "    9547daaf222158b0672a0adab22242cb\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaka8DOE3jDK",
        "outputId": "5f5461a0-3aff-4302-d3fc-00611974676c"
      },
      "outputs": [],
      "source": [
        "! md5sum /content/20250920_epoch30.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Do inference***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvW5nWrIXmG0",
        "outputId": "d3e664cb-a34a-4d02-866a-4fe6e7c7fe3d"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from collections import Counter\n",
        "\n",
        "predictions = []  # store (video, frame_id, pred_class, true_class)\n",
        "\n",
        "for v in video_files_with_label:\n",
        "    video = v['path']\n",
        "    true_class = v['label']\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    frame_id = 0\n",
        "\n",
        "    # ground truth from filename\n",
        "    # true_class = \"abnormal\" if \"abnormal\" in video.lower() else \"normal\"\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_id % frame_interval == 0:\n",
        "            # run inference\n",
        "            results = model.predict(frame, imgsz=1088, verbose=False)\n",
        "\n",
        "            # class names\n",
        "            names = results[0].names\n",
        "\n",
        "            # softmax probabilities\n",
        "            probs = results[0].probs.data.tolist()  # list of floats\n",
        "            prob_dict = {names[i]: float(p) for i, p in enumerate(probs)}\n",
        "\n",
        "            # top-1 prediction\n",
        "            pred_class = names[results[0].probs.top1]\n",
        "\n",
        "            predictions.append((video, frame_id, pred_class, true_class, prob_dict))\n",
        "            print((video, frame_id, pred_class, true_class, prob_dict))\n",
        "\n",
        "        frame_id += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# 3. Frame-level accuracy\n",
        "correct = sum(1 for (_, _, pred, true, _) in predictions if pred == true)\n",
        "total = len(predictions)\n",
        "accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "print(f\"\\nFrame-level results\")\n",
        "print(f\"Total frames tested: {total}\")\n",
        "print(f\"Correct predictions: {correct}\")\n",
        "print(f\"Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Print sample softmax values\n",
        "print(\"\\nSample predictions with softmax:\")\n",
        "for v, f, pred, true, prob_dict in predictions[:5]:\n",
        "    print(f\"{v} frame {f}: pred={pred}, true={true}, probs={prob_dict}\")\n",
        "\n",
        "# 4. Video-level (majority vote)\n",
        "video_results = {}\n",
        "for video in video_files:\n",
        "    preds = [pred for (v, _, pred, _, _) in predictions if v == video]\n",
        "    true_class = \"abnormal\" if \"abnormal\" in video.lower() else \"normal\"\n",
        "    majority_pred = Counter(preds).most_common(1)[0][0]\n",
        "    video_results[video] = (majority_pred, true_class)\n",
        "\n",
        "correct_videos = sum(1 for v, (pred, true) in video_results.items() if pred == true)\n",
        "accuracy_video = correct_videos / len(video_files)\n",
        "\n",
        "print(\"\\nVideo-level results:\")\n",
        "for v, (pred, true) in video_results.items():\n",
        "    print(f\"{v}: predicted={pred}, true={true}\")\n",
        "print(f\"Video-level accuracy: {accuracy_video:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Get representive frames for each video using K-means***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGUiwbFCWDqD",
        "outputId": "4a74f084-eecf-40c9-c3ed-969f1e98dcb3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Number of K-means cluster\n",
        "n_clusters = 3  \n",
        "output_dir = r\"video_frames\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "for video_dict in video_files_with_label:\n",
        "    video_path = video_dict['path']\n",
        "    video_label = video_dict['label']\n",
        "    \n",
        "    video_preds = [(f, pred, true, prob) for (v, f, pred, true, prob) in predictions if v == video_path]\n",
        "    if len(video_preds) == 0:\n",
        "        continue\n",
        "\n",
        "    abnormal_probs = np.array([p[\"abnormal\"] for (_, _, _, p) in video_preds]).reshape(-1, 1)\n",
        "\n",
        "    # K-means\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    kmeans.fit(abnormal_probs)\n",
        "    labels = kmeans.labels_\n",
        "    centers = kmeans.cluster_centers_\n",
        "\n",
        "    representatives = []\n",
        "\n",
        "    # Capture for each representive frame\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    for cluster_id in range(n_clusters):\n",
        "        cluster_indices = np.where(labels == cluster_id)[0]\n",
        "        distances = np.abs(abnormal_probs[cluster_indices] - centers[cluster_id])\n",
        "        closest_idx = cluster_indices[np.argmin(distances)]\n",
        "\n",
        "        frame_id, pred, true, prob_dict = video_preds[closest_idx]\n",
        "        \n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            video_name = os.path.basename(video_path).replace(\".mp4\",\"\").replace(\" \", \"_\")\n",
        "            frame_filename = f\"{video_name}_cluster{cluster_id}_frame{frame_id}.jpg\"\n",
        "            frame_path = os.path.join(output_dir, video_label, video_name, frame_filename)\n",
        "            os.makedirs(os.path.join(output_dir, video_label, video_name), exist_ok=True)\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "        else:\n",
        "            frame_path = None\n",
        "            print(f\"Failed to read frame {frame_id} from {video_path}\")\n",
        "\n",
        "        representatives.append({\n",
        "            \"cluster\": cluster_id,\n",
        "            \"center\": float(centers[cluster_id][0]),\n",
        "            \"frame_id\": frame_id,\n",
        "            \"abnormal_prob\": float(prob_dict[\"abnormal\"]),\n",
        "            \"pred\": pred,\n",
        "            \"true\": true,\n",
        "            \"frame_path\": frame_path\n",
        "        })\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Add representive frame to dict\n",
        "    video_dict[\"representative_frames\"] = representatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Extract text from video using whisper STT model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import whisper\n",
        "\n",
        "stt_model = whisper.load_model(\"base\")\n",
        "\n",
        "for v in video_files_with_label:\n",
        "    video_path = v['path']\n",
        "    label = v['label']\n",
        "    print(video_path)\n",
        "    result = stt_model.transcribe(video_path)\n",
        "    text = result[\"text\"]\n",
        "    print(f\"Video: {video_path}, Label: {label}\")\n",
        "    print(f\"Transcribed Text:\\n{text}\\n\")\n",
        "    v['text'] = text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ***Ask VLM to make a decision based on the given results***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBCh879pCoDZ",
        "outputId": "8f019b9d-70c5-4cc7-f592-6e92b1b1f6b7"
      },
      "outputs": [],
      "source": [
        "import ollama\n",
        "import re\n",
        "\n",
        "# video_files_with_label: representive frame information + extracted text using STT\n",
        "for i, video_dict in enumerate(video_files_with_label):\n",
        "    video_label = video_dict['label']\n",
        "    video_text = video_dict['text']\n",
        "\n",
        "    for j, rep in enumerate(video_dict[\"representative_frames\"]):\n",
        "      while True:\n",
        "        frame_path = rep['frame_path']\n",
        "        frame_pred = rep['pred']\n",
        "        frame_prob = rep['abnormal_prob']\n",
        "        \n",
        "        prompt = f\"\"\"{frame_path}\n",
        "For the image attached, our classification model has recognized it as {frame_pred} with probability {frame_prob:.4f}.\n",
        "The image is one frame of the video.\n",
        "The voice inside video is transcribed as {video_text}\n",
        "In this case, describe what you can see in that picutre and classify yourself if the content of video is normal or abnormal        \n",
        "Your response should end with probability score as 0.0 ~ 1.0\n",
        "If it is normal then the confidence score is near 0.0\n",
        "If it is abnormal then the confidence score is near 1.0\n",
        "Please make sure you should create your own text and evaluate the rate number\n",
        "Remember that your response should end with float number wrapped with two brackets for example\n",
        "[[0.1]]\n",
        "[[0.3]]\n",
        "[[0.86]]\n",
        "        \"\"\"\n",
        "\n",
        "        print(frame_path)\n",
        "        \n",
        "        response = ollama.chat(model=\"openbmb/minicpm-o2.6:8b\", messages=[{'role': 'user', 'content': prompt}] )\n",
        "\n",
        "        text = response['message']['content']\n",
        "\n",
        "        print(text)\n",
        "\n",
        "        rating_text = text[-10:]\n",
        "\n",
        "        numbers = re.findall(r\"\\[\\[([0-9]*\\.?[0-9]+)\\]\\]\", text)\n",
        "        numbers = [float(n) for n in numbers]\n",
        "\n",
        "        # save ollama response and rating into dict\n",
        "        video_files_with_label[i][\"representative_frames\"][j]['ollama_response'] = text\n",
        "        try:\n",
        "            video_files_with_label[i][\"representative_frames\"][j]['ollama_rating'] = numbers[0]\n",
        "            break\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7v7FHnPIT9F",
        "outputId": "fda3d83f-bfe8-43a2-9860-3f8d743211b5"
      },
      "outputs": [],
      "source": [
        "# 확인\n",
        "for v in video_files_with_label:\n",
        "    print(f\"\\nVideo: {v['path']}, Label: {v['label']}, Text: {v['text']}\")\n",
        "    for r in v.get(\"representative_frames\", []):\n",
        "        print(f\"[Cluster {r['cluster']}]\\n\" \n",
        "              f\"center={r['center']:.4f}, frame_sequence={r['frame_id']}\\n\"\n",
        "              f\"abnormal_prob={r['abnormal_prob']:.4f}, pred={r['pred']}, true={r['true']}\\n\"\n",
        "              f\"frame_path={r['frame_path']}\\n\"\n",
        "              f\"ollama_response={r['ollama_response']}\\n\"\n",
        "              f\"ollama_rating={r['ollama_rating']}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cybercop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
